\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\babel@toc {spanish}{}
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {1.1}{\ignorespaces \textbf {Diagrama explicativo del modelo}. Se tienen observaciones del grupo azul y del grupo rojo con una clara separaci\IeC {\'o}n no lineal en las covariables $x_1$ y $x_2$. El modelo busca \textit {entrenar} una funci\IeC {\'o}n $f$ que logre separar lo mejor posible este espacio. Posteriormente, esta separaci\IeC {\'o}n, induce una clasificaci\IeC {\'o}n (0 y 1 correspondiendo a rojo y azul respectivamente) a trav\IeC {\'e}s de la funci\IeC {\'o}n de acumulaci\IeC {\'o}n normal $\Phi $, de ah\IeC {\'\i } a que el modelo sea \textit {probit}.\relax }}{2}{figure.caption.7}
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.1}{\ignorespaces \textbf {Diagrama del modelo.} Se hace una transformaci\IeC {\'o}n no lineal de las covariables $x_j$ a trav\IeC {\'e}s de los par\IeC {\'a}metros $w_j$ y $P_j$. Con los datos transformados $f_j$, se lleva a cabo un modelo probit con funci\IeC {\'o}n liga $\Psi $ para lograr la clasificaci\IeC {\'o}n binaria en $y$.\relax }}{7}{figure.caption.8}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.2}{\ignorespaces \textbf {Esquema de funci\IeC {\'o}n liga $g$}\relax }}{8}{figure.caption.9}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.3}{\ignorespaces \textbf {Modelo de variable latente}\relax }}{9}{figure.caption.10}
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.1}{\ignorespaces Muestro Gibbs para el ejemplo 6 de la Secci\IeC {\'o}n \ref {sec:Test1Ej6}\relax }}{36}{figure.caption.20}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.2}{\ignorespaces Esquema del algoritmo\relax }}{44}{figure.caption.24}
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.1}{\ignorespaces \textbf {Primer ejemplo}. Poco traslape entre puntos\relax }}{48}{figure.caption.27}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.2}{\ignorespaces Separaci\IeC {\'o}n de los grupos por medio de un modelo probit lineal frecuentista\relax }}{50}{figure.caption.29}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.3}{\ignorespaces Visualizaci\IeC {\'o}n de los resultados del modelo\relax }}{52}{figure.caption.32}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.4}{\ignorespaces Transformaciones no lineales para cada dimensi\IeC {\'o}n.\relax }}{53}{figure.caption.33}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.5}{\ignorespaces Ejemplo 2, con $M = 1$, $J = 2$, $K = 0$, derivando en una funci\IeC {\'o}n escalonada\relax }}{55}{figure.caption.36}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.6}{\ignorespaces Ejemplo 3, con $M = 1$, $J = 3$, $K = 0$, derivando en una funci\IeC {\'o}n escalonada\relax }}{56}{figure.caption.37}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.7}{\ignorespaces Ejemplo 4, con $M = 2$, $J = 2$, $K = 1$, el modelo lineal continuo\relax }}{58}{figure.caption.40}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.8}{\ignorespaces Ejemplo 5, con $M = 3$, $J = 3$, $K = 0$, el modelo lineal continuo\relax }}{60}{figure.caption.43}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.9}{\ignorespaces Ejemplo 6, con $M = 4$, $J = 3$, $K = 3$, el modelo lineal continuo\relax }}{61}{figure.caption.44}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.10}{\ignorespaces Trazas e histogramas para los \IeC {\'u}ltimos 1000 valores de las cadenas del muestreo Gibbs, derivadas de la generaci\IeC {\'o}n de los par\IeC {\'a}metros del ejemplo 6\relax }}{64}{figure.caption.46}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.11}{\ignorespaces Medias erg\IeC {\'o}dicas para los par\IeC {\'a}metros. En la primera columna, se muestran las medias erg\IeC {\'o}dicas para toda la cadena, es decir, los $N_{\text {sim}}= 2000$ par\IeC {\'a}metros. En la segunda, se muestran las medias erg\IeC {\'o}dicas para las cadenas con $k^* = 1000$ y $k_{\text {thin}}= 1000$\relax }}{65}{figure.caption.47}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.12}{\ignorespaces Ejemplo 7 con $M = 3$, $J = 4$, $K = 1$\relax }}{67}{figure.caption.49}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.13}{\ignorespaces Ejemplo 8 con $M = 3$, $J = 4$, $K = 1$\relax }}{69}{figure.caption.52}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.14}{\ignorespaces Ejemplo 9 con $M = 3$, $J = 4$, $K = 2$\relax }}{70}{figure.caption.54}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.15}{\ignorespaces Patr\IeC {\'o}n Yin-yang\relax }}{71}{figure.caption.56}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.16}{\ignorespaces Fronteras de varios modelos para datos yin-yang\relax }}{72}{figure.caption.57}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.17}{\ignorespaces An\IeC {\'a}lisis exploratorio para selecci\IeC {\'o}n de variables\relax }}{74}{figure.caption.58}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.18}{\ignorespaces Gr\IeC {\'a}ficos de puntos con algo de ruido para separar las observaciones\relax }}{75}{figure.caption.59}
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
