\documentclass[../Main/Main.tex]{subfiles}

\begin{document}

El objetivo de este capitulo es ilustrar como se pasa de un modelo completamente teórico, a una implementación con código. Específicamente se desarrollará el código en el software estadístico \verb|R|. Además, se hace una exposición  de algunos de los métodos más recientes y sofisticados para la estimación bayesiana y frecuentista de los parámetros del modelo. \\

De forma global, el algoritmo trata de estimar de forma conjunta los cuatro parámetros: $\tsn, \wsn, \betasn$ y $\sigma^2$. A diferencia de la exposición del modelo y dada su estructura, el algoritmo debe de construir de \textit{abajo hacia arriba}. La idea, es que el algoritmo pueda entrenarse de tal forma, que los parámetros reflejen, hacia abajo y hacia lo largo, las estructuras en las covariables, que lleven a predecir si $y$ es exito o fracaso. Se considera, una buena forma de entender el algoritmo es \textit{visualizando} tanto los datos como los objetos que componen el modelo, por lo tanto se hace un paréntesis  notacional.

Tenemos datos $\{(y_i,\xni)\}_{i = 1}^n$ que podemos representar en una tabla (o matriz):

$$\left[\begin{array}{c|ccc} 
y_1 & x_{1,1} & \ldots & x_{1,d} \\ 
\vdots & \vdots & ~ & \vdots \\ 
y_n & x_{n,d} & \ldots & x_{n,d}
\end{array}\right]$$

Donde el vector de observaciones binarias es $\mathbf{y}$, y la matriz de covariables $\mathbf{X}$. Se habla de que la estimación debe reflejar los patrones \textit{hacia abajo} y \textit{hacia lo largo}. Hacia abajo, pues se ve que cada $f_j$ con $j = 1,\ldots,d$ mediante $\wsn$ y $\tsn$ codifica toda la columna de datos $j$. Hacia lo largo, pues la función de proyección $f$ suma (de forma ponderada y a través de las $betasn$), estos efectos individuales hacia lo largo de la tabla de datos. Este balance es fundamental para la correcta predicción.

En forma de pseudocódigo el algoritmo tiene la siguiente forma:

\begin{verbatim}
    Parametros inciales: 
    WHILE (...)
        Transformación de X -> Phi -> F (Función: estimate_PWP)		
        Simulación de betas (Función simulate_beta)
\end{verbatim} 

- Usamos los nodos iniciales en cuantiles determinados.\\
\begin{itemize}
\item taus: HMC
\item $\beta$ Estimar por máxima verosimilitud pero dentro del Gibbs con el método ABC
\item $w's$ BAyesianas + importantes que las betas.
\end{itemize}


\section{Fundamentos de la estadística bayesiana}

- Hacer preambulo bayesiano y justificación de la fislosofía bayesiana
- Sacar posterior-ish
- Hacer derivación de la condicional para $\beta$ paper de Albert + Chibb
- Argumentar por qué es igual para $w$
- Distros a Priori

\section{Especificación para el modelo}
Para los parámetros, se usan las siguientes distribuciones \textit{apriori}:

\begin{align}
	\mathbf{\beta} &= (\beta_0,\beta_1,\ldots,\beta_d)^t \sim N_d(\mu_0, \Sigma_0) \\
	w\superi &= (w\superi_1,\ldots,w\superi_J)^t \sim N_J(\mu\superi_0,\Sigma\superi_0) \quad i=1,\ldots,d
\end{align}

\subsection{Gibbs Sampler para datos binarios}

\section{Funciones de probabilidad condicional completas}


\section{Algoritmo}

- Explicar Alortimo y hacer pseudocódigo de cada sección
- Explicar lógica del algoritmo
- Explicar desarrolo de paquetes en R
- Explicar bien la parte de los residuales y el algorimto backfitting, por que las $f_j$ son arbitrarias y pueden interpolar a los residuales para hacer el ajuste. Esto también explica las $\beta$ pues si se pueden capturar chigón los residuales con una sola dimensión, te vale verga la siguiente :). Yei bitches

\begin{figure}[h]
\centering
\begin{tikzpicture}

% Dibujo nodos
\begin{scope}[
		every node/.style = {fill = white, shape = rectangle }]
		
	\node (t) at (-4,2) {$\t$};
	\node (Phi) at (-2,2) {$\Phi(x,\t)$};
	\node (w) at (-2,0) {$w_j\iterk$};
	\node (F) at (0,2) {$F\iterk$};
	\node (z) at (2,0) {$z\iterk$};	
	\node (beta) at (0,-2) {$\beta\iterk$};
	
\end{scope}

% Flechitas
\begin{scope}[
		every node/.style={fill = white, circle},
	    every edge/.style={draw = black, ->}]
	
	\path (t) edge  node [above] {cte.} (Phi);
	\path (Phi) edge (F);
	\path (F) edge [bend left](z);
	\path (z) edge [bend left](beta);
	\path (beta) edge [bend left](w);
	\path (w) edge[loop left] node [left] 
		{para $j = 1,\ldots,d \;$ }(w);
	\path (w) edge [bend left](F);

\end{scope}
\end{tikzpicture}
\caption{Esquema del algoritmo}
\label{fig:DiagramaAlgoritmo}
\end{figure}



\end{document}